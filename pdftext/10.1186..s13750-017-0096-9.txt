O’Leary et al. Environ Evid (2017) 6:19
DOI 10.1186/s13750-017-0096-9                                                                                         Environmental Evidence
  METHODOLOGY                                                                                                                                         Open Access
Evidence maps and evidence gaps:
evidence review mapping as a method
for collating and appraising evidence reviews
to inform research and policy
Bethan C. O’Leary1* , Paul Woodcock1,2, Michel J. Kaiser3 and Andrew S. Pullin1
   Abstract
   Evidence reviews are a key mechanism for incorporating extensive, complex and specialised evidence into policy and
   practice, and in guiding future research. However, evidence reviews vary in scope and methodological rigour, creating
   several risks for decision-makers: decisions may be informed by less reliable reviews; apparently conflicting interpreta-
   tions of evidence may obfuscate decisions; and low quality reviews may create the perception that a topic has been
   adequately addressed, deterring new syntheses (cryptic evidence gaps). We present a new approach, evidence review
   mapping, designed to produce a visual representation and critical assessment of the review landscape for a particu-
   lar environmental topic or question. By systematically selecting and describing the scope and rigour of each review,
   this helps guide non-specialists to the most relevant and methodologically reliable reviews. The map can also direct
   future research through the identification of evidence gaps (whether cryptic or otherwise) and redundancy (multi-
   ple reviews on similar questions). We consider evidence review mapping a complementary approach to systematic
   reviews and systematic maps of primary literature and an important tool for facilitating evidence-based decision-
   making and research efficiency.
   Keywords: CEESAT, Evidence-based policy, Evidence review map, Gap analysis, Review evaluation, Research
   synthesis, Research methods
Background                                                                                    generates findings that can be selectively used to sup-
Scientific evidence is central to effective environmental                                     port particular conclusions [1, 2]. Against this backdrop,
policymaking and practice but its use requires an appre-                                      non-specialists seeking an overview of particular topics
ciation of the reliability of the evidence base. Primary                                      (e.g. decision-makers and researchers in other fields) are
research forms the backbone of an evidence base; how-                                         increasingly likely to rely on evidence reviews that syn-
ever, non-specialists may lack the resources or exper-                                        thesise evidence across the spectrum of primary litera-
tise to evaluate the appropriateness of methodology and                                       ture related to a specific, policy-relevant question [3–6].
data analysis in primary studies, and to identify trends                                      Evidence reviews (hereafter also referred to as ‘reviews’)
and patterns across multiple studies. Furthermore, the                                        attempt to answer a specific question by aggregating
inherent complexity and variability of natural systems                                        and synthesising the results of primary studies and may
combined with differences in study methods typically                                          include meta-analysis (statistical methods for combining
                                                                                              the magnitude of the outcomes [effect sizes] across differ-
                                                                                              ent data sets addressing the same research question [7])
*Correspondence: bethancoleary@gmail.com                                                      and/or narrative synthesis (use of prose to summarise
1
  Centre for Evidence‑Based Conservation, School of Environment,                              and draw conclusions from primary research which may
Natural Resources and Geography, Bangor University, Gwynedd LL57
2UW, UK
                                                                                              be supplemented by the reviewers’ own experience and
Full list of author information is available at the end of the article                        may include limited quantitative analysis [6]). Evidence
                                              © The Author(s) 2017. This article is distributed under the terms of the Creative Commons Attribution 4.0 International License
                                              (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium,
                                              provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license,
                                              and indicate if changes were made. The Creative Commons Public Domain Dedication waiver (http://creativecommons.org/
                                              publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.

O’Leary et al. Environ Evid (2017) 6:19                                                                          Page 2 of 9
reviews may or may not be conducted within the frame-         most widespread [14, 15], the exponential rise in sys-
work of systematic review methodology [8]. Reviews that       tematic reviews and meta-analyses have been dogged by
only collect and configure the primary literature with        criticisms that many do not follow full systematic review
respect to a broad question, such as systematic maps, are     guidelines, are conflicted by pre-conceived opinions or
not considered as an evidence review in this context.         financial motivations of the authors, and/or have been
   High quality evidence reviews can provide decision-        used to advance industry interests instead of good sci-
makers (or their advisors) with quick and easy access         ence [18]. With awareness and application of systematic
to available evidence on a topic or question of interest.     review methodology expanding in the environmental
However, as with primary research, reviews can differ in      sector, it is vital that ways to maintain and monitor meth-
the rigour of the methods and the reliability of findings     odological standards are developed and applied to ensure
(e.g. [6, 9–12]), and subtle differences in scope may influ-  the objectivity, robustness and value of evidence reviews
ence their applicability to a particular problem. Indeed,     for decision-makers.
the majority of reviews in environmental science are            Tools for critically assessing the methodological reli-
not conducted according to predefined guidelines, but         ability of individual reviews have developed in many
instead apply a range of methods that each promote or         sectors (see [19] and references therein), although lim-
compromise reliability to varying degrees (e.g. [6]). Dif-    ited techniques exist to meaningfully apply and integrate
ferences in methodological reliability amongst reviews on     these assessment protocols to inform environmental
similar topics create several related risks for researchers   policy. Similarly, in other sectors, methods to inform
and decision-makers:                                          non-specialists on available evidence have developed (e.g.
                                                              [20]), but often focus on synthesising findings from the
  (i)   decisions may be informed by less rigorous and/or     systematic review literature [21], or on describing and
        biased reviews because of a lack of systematic colla- appraising systematic reviews and related impact evalu-
        tion of reviews and subsequent appraisal of review    ations [22, 23]. None are designed to describe and criti-
        quality;                                              cally appraise the evidence review literature as a whole
  (ii) apparently conflicting interpretations of evidence     or explicitly consider studies that evaluate environmen-
        among reviews with similar scope may obfuscate        tal outcomes arising from interventions. Accordingly,
        decisions; and                                        new methods to assess and communicate the reliability
  (iii) no new or updated reviews are conducted on a          (including limitations of evidence and methodological
        topic, because researchers and decision-makers are    rigour) and scope of all reviews, systematic and non-
        unaware that the topic lacks a highly rigorous syn-   systematic, could represent a more viable alternative for
        thesis (cryptic evidence gaps [12]).                  summarising evidence reviews in the environmental sec-
                                                              tor. In response, we develop a method that we term ‘evi-
   Clearly communicating the scope and reliability of an      dence review mapping’, to produce a critical overview of
evidence-base to decision-makers and other end-users is       all reviews examining the effectiveness of a given inter-
therefore essential to ensure potential limitations in the    vention and/or impacts of human pressures and man-
conduct of the review(s) being considered are appreci-        agement (e.g. effects of fisheries, impacts of land-use
ated. However, in the absence of communication mech-          change, effectiveness of conservation interventions, etc.).
anisms tailor-made for use within decision-making             This overview includes a systematic assessment of the
processes this can be challenging. Indeed, difficulties in    questions addressed by each review (i.e. scope and rele-
locating relevant evidence and assessing the reliability of   vance) combined with a critical appraisal of review meth-
information gathered are often amongst the main con-          ods (reliability and risk of bias). Outputs from evidence
cerns highlighted by decision-makers [13].                    review mapping are designed specifically to inform non-
   Systematic review and systematic map methodologies         specialists and improve communication of the evidence
were developed in part in recognition of the variable reli-   base by identifying the most relevant and reliable reviews,
ability of reviews [14, 15] and as an attempt to reduce       and to assist future syntheses by highlighting gaps and
these risks and provide high quality evidence synthesis       redundancy (multiple reviews on similar topics) in the
and overviews for decision-makers. Nonetheless, while         review literature. Evidence review maps are tailor-made
systematic reviews are becoming more widespread in            for the environmental decision-making community,
the environmental sector, not all conform to recognised       offering a communication tool that consists of matrices
standards (e.g. [16]) and non-systematic evidence reviews     that summarise the quantity and methodological rigour
still dominate the review landscape [17]. Moreover, in        of reviews on a range of related questions, together with
the medical sector, where systematic review terminol-         a series of supporting tables that provide more detailed
ogy was coined and application of the methodology is          information on the reviews for each particular question.

O’Leary et al. Environ Evid (2017) 6:19                                                                                          Page 3 of 9
Evidence review maps therefore do not aim to answer a         questions then establish the key areas of interest within
specific question but rather intend to enable end-users to    the overall question. More refined questions may be sep-
quickly assess the volume of evidence on the question(s)      arated into broad questions (considering one key area of
of interest, and to obtain an overview of how reliable that   interest) and specific questions (considering paired com-
evidence is.                                                  binations of key areas, based on the population, the inter-
  Here, we describe how to construct evidence review          vention/exposure, and the outcome metrics). Figure 1
maps to inform environmental policy and research, pro-        describes the question hierarchy framework illustrated
viding examples with reference to a study we undertook        with example questions from Woodcock et al. [12]. Com-
in conjunction with developing this methodology [12].         piling a comprehensive list of key areas of interest and
We propose that evidence review mapping offers a com-         their pairwise combinations generates the framework for
plementary approach to systematic reviews and system-         the evidence review map (Fig. 2). The number of refined
atic maps, and suggest that adoption of the methodology       questions represents a pragmatic trade-off between cap-
will facilitate evidence-based policy and practice in con-    turing the many potential influences on the overall ques-
servation and environmental science.                          tion of interest and generating an unmanageably large
                                                              number of specific questions. The scope of the evidence
Methodology—evidence review mapping                           review map will therefore partly depend on the resources
Our approach to evidence review mapping consists of the       available. In addition, while researchers may undertake
following steps: (1) define the overall question of inter-    evidence review mapping independently to guide future
est, construct a series of more refined questions that        studies, maps that are designed to inform policy should
consider key aspects of the overall question, and then        develop the evidence review map framework in consul-
design the search strategy; (2) systematically search and     tation with stakeholders in order to ensure relevance
screen for relevant evidence reviews; (3) assess the scope    through appropriate selection of the population, inter-
of each evidence review against the questions defined         vention/exposure, and outcome metrics to consider.
in step 1; (4) critically appraise the methods of each evi-      Together with the question, it is important to explic-
dence review using a standardised protocol (we use the        itly document the criteria for deciding on whether or not
Collaboration for Environmental Evidence Synthesis            articles are relevant to include to ensure objectivity, trans-
Assessment Tool—CEESAT [19]); and (5) construct the           parency and repeatability during article screening. Once
evidence review map(s). The production of an evidence         these have been defined, an appropriate search strategy
review map integrates some core systematic review             should be developed and detailed within an a priori pro-
methods complemented by several novel approaches              tocol. The search strategy should draw on search meth-
designed specifically to search for, collate, categorise, and ods used for systematic reviews [8] with the search effort
communicate review articles. We provide a description         depending on the scale of the evidence review map, the
of each stage below illustrated, where appropriate, with      volume of subject-specific evidence, and the resources
details adapted from Woodcock et al. [12] who examined        available. Topic-specific search strings should then be
the evidence review landscape for the question ‘What is       narrowed to focus on review articles using terms such as
the effectiveness of marine protected areas as a tool for
mitigating the impacts of fisheries on biodiversity?’
1. Define the question of interest, construct a series
of more refined questions, and then design the search
strategy
To provide the framework for the evidence review map,
the overall question of interest (i.e. scope of the map)
should be established. As with systematic review meth-
odology the question will largely determine the inclusion
criteria for the reviews that form the evidence review
map. Consequently, we recommend that a population,
intervention/exposure, comparator, outcome (PI/ECO)
structure is used to ensure a clearly defined question is
                                                                Fig. 1 Question hierarchy framework used to assess the scope of
developed [8].                                                  reviews for evidence review mapping. Descriptions of the purpose
  Evidence review mapping uses a hierarchy of ques-             of each question level are provided to the left of the triangle. Example
tions to assess the scope of reviews: the overall question      questions based on Woodcock et al. [12] illustrating each level of
sets the scope of the map and a series of more refined          questioning are provided to the right of the triangle

O’Leary et al. Environ Evid (2017) 6:19                                                                                                          Page 4 of 9
                                                                                             Outcome       MPA Char.           Taxa            Region
                                                                                           Abund. Biomass Size    Age      Fish   Invert. Global Tropical
                                                                                Global
                            MPA                                       Region
    Region       Taxa                 Outcome                                   Tropical
                            Char.
  Global      Fish       Size        Abund.                                     Fish
                                                                      Taxa
  Tropical    Invert.    Age         Biomass                                    Invert.
                                                                     MPA        Size
                                                                     Char.
                                                                                Age
                                                                      Outcome
                                                                                Abund.
                                                                                Biomass
  Fig. 2 Schematic illustrating the process of constructing the framework for an evidence review map. Example evidence review map explores
  the effectiveness of marine protected areas (MPAs) for biodiversity conservation. Key components of the overall question are identified in the left
  panel (e.g. population: regional and taxonomic focus, intervention: aspects of MPA design considered, outcome: outcome metrics used to assess
  MPA effectiveness). In the panel on the right, these components are combined to construct the framework for the evidence review map consist-
  ing of broad (dark grey boxes) and specific (light grey boxes) questions. White boxes indicate questions that are not applicable, e.g. global/temperate
  question combinations. Abbreviations in headings refer to: Taxa—Invert invertebrates, MPA Char MPA characteristics, outcome measures—Abund
  abundance (Example adapted from Woodcock et al. [12])
‘AND (review OR “meta-analy*” OR synthes*)’ or using                               taxonomic or geographic scope of the evidence review
appropriate database filters for ‘review articles’ if avail-                       map), or partially consider some questions of interest as
able and known to be reliable, and the databases that will                         part of a broader-ranging review with a different scope
be searched should be documented (see [8] for further                              (this can occur particularly for narrative reviews). Note
information on search strategy design and reporting).                              also that some studies use meta-analytical techniques in
Note that in sectors where systematic reviews are more                             the analysis of long-term primary data (e.g. [26]) or data
widespread, search filters designed to retrieve research                           from selected case studies (e.g. [27]) rather than with the
by study design or focus have been heavily invested in                             aim of comprehensively synthesising published research.
(e.g.     https://sites.google.com/a/york.ac.uk/issg-search-                       As these would not be expected to follow all of the meth-
filters-resource/home). While similar filters exist within                         ods required to produce a rigorous review of primary
search engines commonly used by the environmental sec-                             research (e.g. a priori protocol, comprehensive search-
tor (e.g. Web of Science, Scopus) this functionality is less                       ing, screening), they are unsuitable for evaluation using
well-developed and database-specific so caution is recom-                          CEESAT. However, marking such reviews as ‘borderline
mended before relying solely on their use.                                         relevant’ can assist decision-makers seeking additional
                                                                                   information. Included articles can be assigned a number
2. Systematically search and screen for relevant evidence                          (meta-analyses) or letter (narrative syntheses) to act as a
reviews                                                                            unique identifier when constructing the evidence review
A systematic search and screening process to identify rel-                         map and these should be documented in supporting
evant articles should be undertaken in line with system-                           tables (e.g. Table 1a).
atic review guidelines [8], with searches comprehensively
documented and the repeatability of inclusion decisions                            3. Assess evidence review scope
during screening tested using a kappa test of agreement                            Constructing an evidence review map requires that each
[24, 25] or similar. Inclusion criteria should be refined as                       relevant review is systematically categorised according to
necessary to ensure repeatability [8]. Articles assessed for                       the question(s) addressed (as defined in step 1) and the
relevance at full text should be clearly documented in the                         type of synthesis undertaken [e.g. narrative/qualitative
supporting tables to the map (see step 5 and Table 1a–c)                           (which may include limited quantitative analyses) or meta-
with the reasons for exclusion provided where appro-                               analyses; see [6] for definitions of each]. Note that multi-
priate to maintain transparency. Importantly, in some                              ple questions are often addressed within a single review,
instances, reviews that are excluded may contain                                   and so a single review may be included several times in
related information of potential interest (e.g. outside the                        an evidence review map. The extent to which scope can

O’Leary et al. Environ Evid (2017) 6:19                                                                                                                     Page 5 of 9
Table 1 Example evidence review map supporting tables (a) list of reviews assessed as relevant for inclusion, with review
score and the identifier assigned to each individual review (either a number for meta-analyses, or a letter for narrative
syntheses), (b) scope of meta-analyses that examine broad questions: region, taxa, MPA characteristic and outcome
measure, and (c) scope of narrative syntheses that examine the specific question: broad focus and region. Example
adapted from Woodcock et al. [12]
(a) Reviews assessed
Review identifier                                        Reference                                                        CEESAT score
1                                                        Meta-analytical reference 1
2                                                        Meta-analytical reference 2
a                                                        Narrative reference a
b                                                        Narrative reference b
(b) Scope of meta-analyses
                                                                           Scope                                                         Review identifier
Region                                                                     Global                                                        3, 6–9, 11–14, 16, 17
                                                                           Tropicali                                                     8, 10
Taxa                                                                       Fishii, iii, iv                                               1–3, 5, 6, 8, 10–18
                                                                           Invertebrateii, iii, iv                                       6, 8, 15, 16, 18
MPA characteristic                                                         Sizei, vi                                                     1–3, 5, 6, 8, 10, 11, 15, 17, 18
                                                                           Agev                                                          1–3, 5, 7, 10–13, 15, 17, 18
Outcome measure                                                            Abundance                                                     1–18
                                                                           Biomassvii, viii, ix                                          4–8, 17, 18
(c) Scope of narrative syntheses
                                                Scope                                                  FOCUS
                                                                                                       Biodiversity                                         Fisheries
Region                                          Global                                                 b, c, f, h, i                                        b, e, f, g, h, i
                                                Temperate                                              d                                                    d
                                                Tropical                                               a
Superscript roman numerals adjacent to ‘Scope’ in (b) are used to refer the end-user to relevant notes on additional reviews that consider the question but with less
than the required number of primary studies or without reporting effect sizes
be objectively categorised is influenced by the methods                                    included as potential confounding variables but statis-
employed in the review. Whilst a meta-analysis can usually                                 tics (e.g. effect sizes) are not reported would not be con-
be objectively categorised as addressing a particular ques-                                sidered as directly addressing a given question [12]. A
tion based on whether or not effect sizes are presented,                                   threshold for the minimum number of primary studies a
there is no such obvious distinction in many narrative                                     meta-analysis must contain to be categorised as address-
reviews, in which questions could be addressed through                                     ing a particular question could be set. The minimum
varying amounts of text with varying degrees of relevance                                  threshold is highly context-specific (e.g. relating to the
and supporting references. This problem is exacerbated                                     quality of primary research, typical effect sizes and vari-
because the scope of narrative reviews is often broader                                    ances, etc.) and consequently requires a transparent case-
than meta-analytical reviews. Reliable categorisation of                                   by-case judgement for each evidence review map. Where
scope is thus possible in greater detail for meta-analyses                                 a threshold is considered appropriate, reviews that do not
than for narrative syntheses. The assessment of review                                     meet this threshold should be noted as partially address-
scope should therefore be undertaken in two parts, firstly                                 ing the question, thereby allowing articles that are based
considering reviews that apply meta-analytical techniques                                  on a small volume of primary research to be identified.
and secondly reviews that use narrative synthesis.                                            Categorisation of narrative syntheses should be under-
   Categorisation of meta-analyses as addressing particu-                                  taken wherever possible using the refined questions
lar questions requires effect sizes to be quoted directly,                                 initially devised in step 1. However, because narrative
presented graphically or used in statistical tests of rela-                                syntheses often cover a range of topics in varying depths,
tionships [12]. Instances where relevant terms are                                         such fine-scale categorisation may not be possible and so

O’Leary et al. Environ Evid (2017) 6:19                                                                                                                                   Page 6 of 9
    a                                 Outcome        MPA Char.                  Taxa            Region          b                     Broad Focus     MPA Char.        Region
                                   Abund. Biomass   Size       Age       Fish       Invert. Global Tropical                           BD.    Fish.   Size   Conn.   Global Tropical
                                                *                                          *
                        Global                                                                                             Global                            0
    Region                                                                                                      Region
                        Tropical                                                                                           Tropical            0
                                        *       *                               *
                                                                                                                MPA Char
                        Fish                                                                                               Size
    Taxa
                                        *       *          *                             *
                        Invert.                                                                                            Conn.               0
                                                *          *
    Outcome MPA Char.
                        Size                                                                                               BD.
                                                                                                               Broad
                                                *                    *                                         Focus
                        Age                                                                                                Fish.
                        Abund.
                                                *
                        Biomass
  Fig. 3 Example a meta-analytical and b narrative evidence review map illustrating the marine protected area review landscape. The matrix should
  be read using combinations from the top and left headings to form the particular question of interest. Each individual doughnut chart describes the
  number of reviews addressing a question, and the proportion of reviews that are high (26.5+; black), moderate (13.5–26; grey) and low (≤13; white)
  scoring. Star symbols represent where one or more reviews have been identified that partially address the particular question. Full details identifying
  reviews that address a particular question are reported in the supporting tables. Abbreviations in headings refer to: Taxa—Invert invertebrates MPA
  Char MPA characteristics, outcome measures—Abund abundance, broad focus—BD biodiversity, Fish fisheries (Example adapted from Woodcock
  et al. [12])
questions may need to be broadened to more accurately                                                    where appropriate (e.g. see [6]). Reviews should be inde-
reflect narrative review content (e.g. by broad area of                                                  pendently scored by two assessors and the repeatability
focus etc. see Fig. 3; [12]).                                                                            of the assessment evaluated with a weighted kappa test
                                                                                                         of agreement [24, 25] or similar to take into account the
4. Critically appraise the methods of each evidence review                                               magnitude of any disagreements, e.g. a 1-0 disagreement
using a standardised protocol                                                                            is ranked as magnitude 1, whereas a 3-0 disagreement is
The assessment of review methodology forms the penul-                                                    ranked as magnitude 3 [10, 28]. Disagreements between
timate stage in evidence review map development. A                                                       assessors should be discussed and where these reflect
standardised protocol designed to assess the reliability                                                 uncertainty over whether or not a criterion was met, the
of environmental evidence reviews should be utilised to                                                  average score from the two assessors should be used.
critically appraise the methodological rigour of each rel-                                                  There are a number of possible approaches to interpret-
evant review in a consistent manner. For this purpose we                                                 ing CEESAT scores (see [19] for further discussion) how-
recommend the Collaboration for Environmental Evi-                                                       ever, we currently recommend dividing total CEESAT
dence Synthesis Assessment Tool (CEESAT; [19]). The                                                      scores into three categories 0–13, 13.5–26 and 26.5+,
current version of CEESAT (available at http://www.envi-                                                 loosely representing low, intermediate/moderate and
ronmentalevidence.org/review-appraisals) consists of 13                                                  high methodological reliability. The boundaries for these
criteria relating to the reliability (combining objectivity,                                             categories reflect an average score across the 13 criteria
transparency, and comprehensiveness) of reviews (see                                                     of 0–1, 1–2 and 2–3. Note that while these boundaries
[19] for details), and achieves good repeatability when                                                  may change as further guidance on scoring interpretation
independent assessments of the same review are com-                                                      becomes available, or if certain aspects of review conduct
pared [6, 12, 19]. For each criterion, reviews receive 3                                                 are prioritised by those conducting an evidence review
points, 1 point, or 0 points. Scores therefore range from                                                map, the methodology for incorporating scores into evi-
0 to 39: the higher the score, the greater the confidence                                                dence review mapping will remain valid.
that the review methodology is robust and reliable in
terms of repeatability and risk of bias. Importantly, while                                              5. Construct the evidence review map
certain criteria within CEESAT require statistical analysis                                              Finally, using information from steps 3 and 4, a series
to score highly, points for these criteria are available to                                              of evidence review maps may be constructed to visually
narrative syntheses [6, 19]. Furthermore, high scores are                                                represent the review landscape for the overall question of
available equally to narrative syntheses and meta-analy-                                                 interest (Fig. 3). Separate maps should be constructed to
ses for most of the criteria enabling narrative syntheses                                                describe meta-analyses and narrative reviews to ensure
to be assessed as having high reliability (a score of 26.5+)                                             similar levels of objectivity in review categorisation

O’Leary et al. Environ Evid (2017) 6:19                                                                         Page 7 of 9
within each map. Evidence review maps should be con-         of all types continuing to increase, evidence review maps
structed using refined questions as defined in step 1 for    provide the opportunity to visualise the review land-
meta-analyses and those determined in steps 1 and/or         scape for an overall question of interest and to guide
3 for narrative reviews. Note that for the example here,     non-specialists to more relevant and reliable reviews.
none of the narrative syntheses provided sufficient infor-   We consider evidence review mapping a complemen-
mation to score highly when assessed with CEESAT (e.g.       tary approach to systematic reviews and systematic maps
see [12]) and, as a consequence, the narrative evidence      and an important tool for facilitating evidence-based
review map shows all reviews to be of low reliability        decision-making.
(Fig. 3b). This reflects the specific evidence base for MPA    Evidence review mapping relies on systematic
effectiveness rather than being a consequence of differ-     searching, transparent decisions on article inclusion
ences in the way in which CEESAT evaluates narrative         and exclusion, objective assessment of review scope
syntheses vs. meta-analyses [12].                            and a standardised and repeatable protocol for criti-
   Evidence review maps consist of a matrix that com-        cally appraising individual reviews. Application of our
bines information on the number of reviews addressing        approach has illustrated the variable scope and reliabil-
a given question and the methodological rigour of each       ity of published evidence reviews and the need to ensure
review, enabling end-users to see what evidence there        non-specialists can locate the most relevant and rigor-
is on the question(s) they are interested in. The matrix     ous reviews on particular questions of interest, as well
overview is supported by a series of tables that allow       as indicating how planned reviews can be designed to
the most rigorous reviews on each question to be iden-       complement the existing body of reviews [12]. We believe
tified. The matrix should be read using combinations         this approach and its outputs will be useful to decision-
from the top and left headings to form a particular ques-    makers, advisors and knowledge brokers wishing to use
tion. Doughnut pie charts can be created to represent        evidence in environmental policy and practice, as well
(1) the total number of reviews that address each indi-      as to researchers looking to contribute to the evidence
vidual question (included in the centre of the doughnut      base through targeted evidence synthesis. Our approach
pie) and (2) the proportion of those reviews that are of     to evidence review mapping could be applied widely to
high, medium or low methodological reliability. Sym-         many important questions in environmental policy, as an
bols should be used to identify where reviews have been      ‘evidence service’ with considerable benefits for research
categorised as partially addressing a particular ques-       efficiency and evidence-based policy.
tion (due to the threshold for number of included pri-
mary research articles not being met). The format of the     Considerations for conducting evidence review maps
matrix means that some questions will not be applicable;     While evidence review mapping is a valuable tool, it
these areas should be left blank. Full details of reviews    will pose some challenges to those wishing to construct
included for each specific question, together with details   such maps. Most notably, decisions over whether or
of any reviews that partially address a given question       not reviews are relevant for inclusion require subjective
should then be provided in a series of supporting tables     judgement. This difficulty arises particularly in narrative
(e.g. see Table 1b, c; [12]).                                syntheses, because there is a continuum between stud-
   Supporting tables should include: (1) details for the     ies that exclusively review the findings from relevant pri-
search strategy; (2) a list of relevant reviews with their   mary research versus studies that have a very broad scope
unique identifier and review score; (3) a list of excluded   or a more conceptual focus and are therefore less appro-
studies with reasons for exclusion; and (4) a series of      priate for evidence review mapping. Because most sub-
tables detailing the meta-analyses and narrative synthe-     jective decisions on relevance relate to narrative reviews,
ses examining each refined question, designed to direct      altering these decisions would not affect the meta-ana-
end-users to the most relevant and rigorous review for       lytical evidence review map and, while they might adjust
their requirements.                                          the average narrative review score for a given question,
                                                             they are unlikely to markedly change the conclusions on
Discussion                                                   review rigour and scope. Nonetheless, ensuring transpar-
Understanding the reliability of an evidence base is cen-    ency of decisions at all stages of evidence review mapping
tral to effective decision-making and developing mecha-      by documentation in the supporting tables is an impor-
nisms for communicating this to decision-makers is           tant component of the methodology to enable end-users
therefore essential. While systematic review methodol-       to understand and challenge the decisions made over
ogy is considered a key tool for unbiased evidence syn-      article inclusion and categorisation. Additionally, some
thesis, the reliability of evidence reviews will continue to methodologically distinct forms of review, such as quali-
vary for many reasons [18]. With the number of reviews       tative syntheses or mixed methods may not be suitable

O’Leary et al. Environ Evid (2017) 6:19                                                                                                   Page 8 of 9
for appraisal using CEESAT and including such reviews         Conclusions
will require further research and development.                As the review literature continues to expand, it will
  Evidence review maps rely on the use of a standardised      become increasingly difficult for non-specialists to locate
scoring tool to assess the reliability of reviews. Like other all relevant evidence reviews. Furthermore, when select-
scoring tools, CEESAT assesses the likelihood that a          ing reviews to inform decision-making, non-specialists
review is reliable on the basis of key attributes relating to may lack the resources to critically appraise all avail-
available evidence, conduct and reporting standards, and      able syntheses and may instead treat all evidence reviews
does not guarantee the reliability of a review against other  equally, or use measures of review rigour that are ques-
factors such as author errors. In addition, total scores of   tionable and/or subjective (e.g. journal impact factor,
reviews can mask specific strengths or weaknesses across      citation count, author reputation). However, we, and oth-
criteria. A breakdown of scoring across individual crite-     ers (e.g. [6, 9, 12, 30]), have found that published evidence
ria may therefore be a useful subsequent output to ensure     reviews in the environmental sector vary considerably in
that decision-makers can gauge the extent to which the        reliability and scope, which presents challenges to those
strengths and weaknesses of a review make it suitable         wishing to undertake evidence-based decision-making.
for the intended use (see [19] for a detailed discussion of   We therefore propose that evidence review mapping
important caveats in applying and interpreting CEESAT         represents an important method for communicating the
scores). Researchers who wish to undertake evidence           reliability and scope of all reviews on a particular topic
review mapping may wish to use alternative boundaries         to non-specialists, thereby facilitating evidence-based
and/or weightings of criteria to represent reliability than   policy and practice in conservation and environmental
those suggested here if certain aspects of review conduct     science.
are viewed as particularly important to the end-user.
                                                              Authors’ contributions
In such instances, clear rationale for amending these         Led the research: BCO, PW, ASP. Wrote and reviewed the manuscript: BCO, PW,
boundaries and/or weightings should be provided as part       MJK, ASP. All authors read and approved the final manuscript.
of the evidence review map.
                                                              Author details
  There may be instances in which more than one high          1
                                                                Centre for Evidence‑Based Conservation, School of Environment, Natural
scoring review addresses a particular question. In such       Resources and Geography, Bangor University, Gwynedd LL57 2UW, UK. 2 Joint
situations, further assessment could consider the con-        Nature Conservation Committee, Monkstone House, Peterborough PE1 3JY,
                                                              UK. 3 School of Ocean Sciences, Bangor University, Menai Bridge, Anglesey
sistency in findings between reviews (noting that direct      LL59 5AB, UK.
comparisons of specific results can be misleading if subtle
differences in review scope are not identified). If results   Acknowledgements
                                                              We thank our potential end-users Ally Dingwall (Sainsbury’s), Tom Pickerell
differ between reviews, potential reasons for ambiguity       (Seafish, Seafood Watch), Jon Harman (Seafish), Mike Mitchell, David Parker
could then be considered, and further work targeted to        (Young’s Seafood), David Jarrad (Shellfish Association of Great Britain) for their
examine the evidence base where reasons for discrepancy       contribution to discussions regarding review reliability. This project was sup-
                                                              ported in part by a UK Natural Environmental Research Council Knowledge
are unclear. In the latter situation, systematic reviews,     Exchange Grant NE/J006386/1.
containing meta-analytical techniques wherever possible,
and/or targeted and well-designed primary research are        Competing interests
                                                              The authors declare that they have no competing interests.
recommended to ensure that policymaking is informed
by reliable evidence that is robust and methodologically      Availability of data and materials
rigorous [29].                                                All data generated or analysed during this study are included in the published
                                                              article Woodcock, P., O’Leary, B.C., Kaiser, M.J., Pullin, A.S. (in press) Your
  Finally, note that unlike ‘review of reviews’ that aim      evidence or mine? Systematic evaluation of reviews of marine protected area
to provide a synthesis of evidence from more than one         effectiveness. Fish and Fisheries. Doi: 10.1111/faf.12196 (and its Additional
review, evidence review maps do not set out to answer         files).
a specific question but rather seek to provide an over-       Funding
view of the existing review evidence base. Consequently,      This work was supported in part by a UK Natural Environmental Research
maps are intended to guide decision-makers to relevant        Council Knowledge Exchange Grant NE/J006386/1. No other grants from
                                                              funding agencies in the public, commercial, or not-for-profit sectors were
information and illustrate strengths and weaknesses in        received.
the evidence base, rather than to directly provide policy
recommendations or guidelines. Future work that may           Publisher’s Note
add value to evidence review maps might include devel-        Springer Nature remains neutral with regard to jurisdictional claims in pub-
oping user-friendly summaries on included reviews, or         lished maps and institutional affiliations.
reports summarising the findings of the evidence review       Received: 12 January 2017 Accepted: 11 July 2017
map together with implications for policy and research.

O’Leary et al. Environ Evid (2017) 6:19                                                                                                               Page 9 of 9
References                                                                       17. Haddaway NR, Woodcock P, Macura B, Collins A. Making literature reviews
1. Egger M, Smith GD. Bias in location and selection of studies. BMJ.                more reliable through application of lessons from systematic reviews.
    1998;316:61–6.                                                                   Conserv Biol. 2015;29(6):1596–605.
2. Schott GD. The reference: more than a buttress of the scientific edifice. J R 18. Ioannidis JPA. The mass production of redundant, misleading,
    Soc Med. 2003;96:191–3.                                                          and conflicted systematic reviews and meta-analyses. Milbank Q.
3. Seavy NE, Howell CA. How can we improve information delivery to                   2016;94:485–514.
    support conservation and restoration decisions? Biodivers Conserv.           19. Woodcock P, Pullin AS, Kaiser MJ. Evaluating and improving the reliability
    2010;19:1261–7.                                                                  of evidence syntheses in conservation and environmental science: a
4. Cook CN, Carter RW, Fuller RA, Hockings M. Managers consider multiple             methodology. Biol Conserv. 2014;176:54–62.
    lines of evidence important for biodiversity management decisions. J         20. Miake-Lye IM, Hempel S, Shanman R, Shekelle PG. What is an evidence
    Environ Manage. 2012;113:341–6.                                                  map? A systematic review of published evidence maps and their defini-
5. Pullin AS, Knight AT, Stone DA, Charman K. Do conservation managers               tions, methods and products. Syst Rev. 2016;5:28.
    use scientific evidence to support their decision-making? Biol Conserv.      21. Caird J, Sutcliffe K, Kwan I, Dickson K, Thomas J. Mediating policy-relevant
    2004;119:245–52.                                                                 evidence at speed: are systematic reviews of systematic reviews a useful
6. O’Leary BC, Kvist K, Bayliss HR, Derroire G, Healey JR, Hughes K, et al. The      approach. Evid Policy. 2015;11:81–7.
    reliability of evidence review methodology in environmental science and      22. Snilstveit B, Vojtkova M, Bhavsar A, Gaarder M. Evidence gap maps—a
    conservation. Environ Sci Policy. 2016;64:75–82.                                 tool for promoting evidence-informed policy and prioritizing future
7. Koricheva J, Gurevitch J, Mengersen K. Handbook of meta-analysis in               research. World bank policy research working paper no. 6725. 2013.
    ecology and evolution. Princeton: Princeton University Press; 2013.          23. McKinnon MC, Cheng SH, Garside R, Masuda YJ, Miller DC. Sustainability:
8. CEE, Guidelines for systematic review and evidence synthesis in environ-          map the evidence. Nature. 2015;528:185–7.
    mental management. Version 4.2. Environmental evidence. 2013.                24. Cohen J. A coefficient of agreement for nominal scales. Educ Psychol
9. Roberts PD, Stewart GB, Pullin AS. Are review articles a reliable source of       Meas. 1960;20:37–46.
    evidence to support conservation and environmental management? A             25. Landis JR, Koch GG. The measurement of observer agreement for cat-
    comparison with medicine. Biol Conserv. 2006;132(4):409–23.                      egorical data. Biometrics. 1997;33:159–74.
10. Shea BJ, Bouter LM, Peterson J, Boers M, Andersson N, Ortiz Z, et al. Exter- 26. Ojeda-Martinez C, Bayle-Sempere JT, Sanchez-Jerez P, Forcada A, Valle
    nal validation of a measurement tool to assess systematic reviews. PLoS          C. Detecting conservation benefits in spatially protected fish popu-
    ONE. 2007;2:e1350.                                                               lations with meta-analysis of long term monitoring data. Mar Biol.
11. Philibert A, Loyce C, Makowski D. Assessment of the quality of meta-             2007;151:1153–61.
    analysis in agronomy. Agric Ecosyst Environ. 2012;148:72–82.                 27. Vandeperre F, Higgins RM, Sanchez-Meca J, Maynou F, Goni R, Martin-
12. Woodcock P, O’Leary BC, Kaiser MJ, Pullin AS. Your evidence or mine?             Sosa P, et al. Effects of no-take area size and age of marine protected
    Systematic evaluation of reviews of marine protected area effectiveness.         areas on fisheries yields: a meta-analytical approach. Fish Fish.
    Fish Fish. 2017;18(4):668–81.                                                    2011;12:412–26.
13. Holmes J, Clark R. Enhancing the use of science in environmental policy-     28. Viera AJ, Garrett JM. Understanding interobserver agreement: the kappa
    making and regulation. Environ Sci Policy. 2008;11:702–11.                       statistic. Fam Med. 2005;37:360–3.
14. Cook DJ, Mulrow CD, Haynes RB. Systematic reviews: synthesis of best         29. Pullin AS, Knight TM. Doing more good than harm—building an
    evidence for clinical decisions. Ann Intern Med. 1997;126:376–80.                evidence-base for conservation and environmental management. Biol
15. Chalmers I, Hedges LV, Cooper H. A brief history of research synthesis.          Conserv. 2009;142:931–4.
    Eval Health Prof. 2002;25:12–37.                                             30. Huntington BE. Confronting publication bias in marine reserve meta-
16. O’Leary BC, Bayliss HR, Haddaway NR. Beyond PRISMA: systematic reviews           analyses. Front Ecol Environ. 2011;9:375–6.
    to inform marine science and policy. Mar Policy. 2015;62:261–3.
                                                                                     Submit your next manuscript to BioMed Central
                                                                                     and we will help you at every step:
                                                                                       • We accept pre-submission inquiries
                                                                                       • Our selector tool helps you to find the most relevant journal
                                                                                       • We provide round the clock customer support
                                                                                       • Convenient online submission
                                                                                       • Thorough peer review
                                                                                       • Inclusion in PubMed and all major indexing services
                                                                                       • Maximum visibility for your research
                                                                                       Submit your manuscript at
                                                                                       www.biomedcentral.com/submit

